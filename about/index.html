---
layout: default
title: About
---

<div class="container agent-page">
    <a href="{{ '/' | relative_url }}" class="back-btn">
        <i class="fa-solid fa-arrow-left"></i> Back to Home
    </a>

    <div class="agent-header">
        <h1>About LOLAI</h1>
        <div class="agent-meta">
            <span class="badge badge-cat">Documentation</span>
            <span class="badge vendor">Open Source</span>
        </div>
    </div>

    <section class="agent-section">
        <h2>Mission</h2>
        <div class="content-wrapper">
            <p>
                LOLAI (Living Off The Land AI) aims to document and catalog AI agents and assistants that can be weaponized,
                abused, or exploited in both enterprise and personal computing environments. As AI agents become more prevalent
                and powerful, understanding their security implications is crucial for defenders and security professionals.
            </p>
        </div>
    </section>

    <section class="agent-section">
        <h2>What We Track</h2>
        <div class="content-wrapper">
            <p>We focus on documenting AI agents with the following characteristics:</p>
            <ul>
                <li><strong>System Access:</strong> Agents with file system, terminal, or API access</li>
                <li><strong>Code Execution:</strong> Ability to execute arbitrary code or commands</li>
                <li><strong>Autonomous Behavior:</strong> Agents that can operate without constant human oversight</li>
                <li><strong>Network Capabilities:</strong> Tools with network communication abilities</li>
                <li><strong>Plugin/Extension Systems:</strong> Platforms that support third-party extensions</li>
            </ul>
        </div>
    </section>

    <section class="agent-section">
        <h2>Inspiration</h2>
        <div class="content-wrapper">
            <p>LOLAI is inspired by successful "Living Off The Land" projects:</p>
            <ul>
                <li>
                    <strong><a href="https://gtfobins.github.io/" target="_blank" rel="noopener noreferrer">GTFOBins</a></strong> -
                    Unix binaries that can be used to bypass local security restrictions
                </li>
                <li>
                    <strong><a href="https://lolbas-project.github.io/" target="_blank" rel="noopener noreferrer">LOLBAS</a></strong> -
                    Living Off The Land Binaries, Scripts and Libraries for Windows
                </li>
                <li>
                    <strong><a href="https://www.loldrivers.io/" target="_blank" rel="noopener noreferrer">LOLDrivers</a></strong> -
                    Windows drivers used by attackers to bypass security software
                </li>
                <li>
                    <strong><a href="https://lolrmm.io/" target="_blank" rel="noopener noreferrer">LOLRMM</a></strong> -
                    Remote monitoring and management tools used in attacks
                </li>
            </ul>
        </div>
    </section>

    <section class="agent-section">
        <h2>Methodology</h2>
        <div class="content-wrapper">
            <p>Each agent entry includes:</p>
            <ul>
                <li><strong>Attack Vectors:</strong> Documented methods of abuse with practical examples</li>
                <li><strong>Technical Details:</strong> Capabilities, permissions, and system access</li>
                <li><strong>MITRE ATT&CK Mapping:</strong> Alignment with industry-standard attack frameworks</li>
                <li><strong>Detection Methods:</strong> Artifacts, logs, and indicators of compromise</li>
                <li><strong>Prevention Strategies:</strong> Mitigation techniques and best practices</li>
            </ul>
        </div>
    </section>

    <section class="agent-section">
        <h2>Use Cases</h2>
        <div class="content-wrapper">
            <p>LOLAI serves multiple audiences:</p>
            <ul>
                <li><strong>Security Teams:</strong> Understand risks of AI agents in your environment</li>
                <li><strong>Penetration Testers:</strong> Reference for red team engagements</li>
                <li><strong>Developers:</strong> Security considerations when building AI-powered tools</li>
                <li><strong>Researchers:</strong> Catalog of AI security techniques and attack patterns</li>
                <li><strong>Policy Makers:</strong> Information for AI governance and compliance</li>
            </ul>
        </div>
    </section>

    <section class="agent-section">
        <h2>Contributing</h2>
        <div class="content-wrapper">
            <p>LOLAI is an open-source community project. We welcome contributions:</p>
            <ul>
                <li>Submit new AI agents with documented attack vectors</li>
                <li>Improve existing documentation</li>
                <li>Add detection methods and IOCs</li>
                <li>Report issues or suggest improvements</li>
            </ul>
            <p style="margin-top: 1rem;">
                Visit our <a href="https://github.com/lolai-project/lolai-project.github.io" target="_blank" rel="noopener noreferrer">GitHub repository</a>
                to get started.
            </p>
        </div>
    </section>

    <section class="agent-section">
        <h2>Disclaimer</h2>
        <div class="content-wrapper">
            <p style="padding: 1rem; background: rgba(248, 81, 73, 0.1); border-left: 3px solid var(--accent-danger); border-radius: 4px;">
                <strong>⚠️ Important:</strong> This project is for <strong>educational and defensive purposes only</strong>.
                The techniques documented here should only be used in authorized security testing, research, or defensive contexts.
                Unauthorized access to computer systems is illegal.
            </p>
        </div>
    </section>

    <div class="agent-footer">
        <a href="{{ '/' | relative_url }}" class="btn-back">
            <i class="fa-solid fa-arrow-left"></i> Back to Home
        </a>
    </div>
</div>
